{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ItemID  Sentiment                                      SentimentText\n",
      "0       1          0                       is so sad for my APL frie...\n",
      "1       2          0                     I missed the New Moon trail...\n",
      "2       3          1                            omg its already 7:30 :O\n",
      "3       4          0            .. Omgaga. Im sooo  im gunna CRy. I'...\n",
      "4       5          0           i think mi bf is cheating on me!!!   ...\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"train.csv\", encoding = 'latin')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99989, 3)\n",
      "0.5646321095320486\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace = True)\n",
    "print(data.shape)\n",
    "print(data['Sentiment'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (65017,)\n",
      "X_val: (19973,)\n",
      "X_test: (14999,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['SentimentText'], data['Sentiment'], test_size=0.15, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.235, random_state=1)\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_val:\", X_val.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', 'abit', 'allanfrancisco', 'anniespajamas', 'ayekaygee', 'biggbybob', 'bryantma', 'character', 'companymancomic', 'drives', 'gstlrf', 'kip', 'n8ai', 'qdo', 'soulfish', 'unforgettable']\n",
      "Feature count: 78872\n"
     ]
    }
   ],
   "source": [
    "countVect = CountVectorizer().fit(X_train)\n",
    "print(countVect.get_feature_names()[::5000])\n",
    "print(\"Feature count:\", len(countVect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.71, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized = countVect.transform(X_train)\n",
    "model = LogisticRegression(C = 0.71)\n",
    "model.fit(X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(countVect.transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score \n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7696890802583488\n",
      "f1_score(weighted): 0.7678701423516031\n",
      "average_precision_score(weighted): 0.7431107020580949\n",
      "recall_score(weighted): 0.7696890802583488\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_val, predictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_val, predictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_val, predictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_val, predictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredictions = model.predict(countVect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7720514700980066\n",
      "f1_score(weighted): 0.7704230429407638\n",
      "average_precision_score(weighted): 0.7429734974934948\n",
      "recall_score(weighted): 0.7720514700980066\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_test, testPredictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_test, testPredictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_test, testPredictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_test, testPredictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['sad' 'inaperfectworld' 'dontyouhate' 'sucks' 'poor' 'sadly' 'rip'\n",
      " 'cancelled' 'missing' 'bummer']\n",
      "\n",
      "Largest Coefs: \n",
      "['musicmonday' 'welcome' 'bear' 'congrats' 'followfriday' 'worries'\n",
      " 'congratulations' 'worry' 'woohoo' 'thanks']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(countVect.get_feature_names())\n",
    "\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|+*,#;]')\n",
    "BAD_SYMBOLS_RE = re.compile('[^0-9a-z @_]')\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def text_prepare(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(REPLACE_BY_SPACE_RE, \" \", text)\n",
    "    text = re.sub(BAD_SYMBOLS_RE, \"\", text)\n",
    "    text_tokens = word_tokenize(text)\n",
    "    filtered_sentence = \"\"\n",
    "    for w in text_tokens:\n",
    "        if w not in STOPWORDS:\n",
    "            filtered_sentence += w + \" \"\n",
    "    return filtered_sentence[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train = [text_prepare(x) for x in X_train]\n",
    "X2_val = [text_prepare(x) for x in X_val]\n",
    "X2_test = [text_prepare(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@', 58959), ('im', 7291), ('good', 3805), ('like', 3611), ('get', 3446), ('u', 3329), ('lol', 3236), ('dont', 3174), ('quot', 3128), ('know', 2935)]\n"
     ]
    }
   ],
   "source": [
    "words_counts = {}\n",
    "\n",
    "for tweet in X2_train:\n",
    "    for word in tweet.split():\n",
    "        words_counts[word] = words_counts.setdefault(word, 0) + 1\n",
    "\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT_SIZE = 5000\n",
    "\n",
    "most_common_words = sorted(words_counts.items(), key=lambda x: x[1], reverse=True)[:DICT_SIZE]\n",
    "\n",
    "WORDS_TO_INDEX = {}\n",
    "i = 0\n",
    "for entry in most_common_words:\n",
    "    WORDS_TO_INDEX[entry[0]] = i\n",
    "    i += 1\n",
    "\n",
    "INDEX_TO_WORDS = {}\n",
    "i = 0\n",
    "for entry in most_common_words:\n",
    "    INDEX_TO_WORDS[i] = entry[0]\n",
    "    i += 1\n",
    "\n",
    "ALL_WORDS = WORDS_TO_INDEX.keys()\n",
    "\n",
    "def my_bag_of_words(text, words_to_index, dict_size):\n",
    "    result_vector = np.zeros(dict_size)\n",
    "    for word in text.split():\n",
    "        if word in words_to_index:\n",
    "            result_vector[words_to_index[word]] += 1\n",
    "    return result_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as sp_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape  (65017, 5000)\n",
      "X_val shape  (19973, 5000)\n",
      "X_test shape  (14999, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X2_train])\n",
    "X_val_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X2_val])\n",
    "X_test_mybag = sp_sparse.vstack([sp_sparse.csr_matrix(my_bag_of_words(text, WORDS_TO_INDEX, DICT_SIZE)) for text in X2_test])\n",
    "print('X_train shape ', X_train_mybag.shape)\n",
    "print('X_val shape ', X_val_mybag.shape)\n",
    "print('X_test shape ', X_test_mybag.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(C = 0.5).fit(X_train_mybag, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = classifier.predict(X_val_mybag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7551194112051269\n",
      "f1_score(weighted): 0.7519824642903692\n",
      "average_precision_score(weighted): 0.727193898957285\n",
      "recall_score(weighted): 0.7551194112051269\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_val, predictions2))\n",
    "print(\"f1_score(weighted):\", f1_score(y_val, predictions2, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_val, predictions2, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_val, predictions2, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredictions2 = classifier.predict(X_test_mybag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7576505100340023\n",
      "f1_score(weighted): 0.7550034504487017\n",
      "average_precision_score(weighted): 0.7276347273884347\n",
      "recall_score(weighted): 0.7576505100340023\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_test, testPredictions2))\n",
    "print(\"f1_score(weighted):\", f1_score(y_test, testPredictions2, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_test, testPredictions2, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_test, testPredictions2, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9308\n"
     ]
    }
   ],
   "source": [
    "tfidfVect = TfidfVectorizer(min_df=5).fit(X_train)\n",
    "print(len(tfidfVect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.2, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfX_train_vectorized = tfidfVect.transform(X_train)\n",
    "\n",
    "tfmodel = LogisticRegression(C = 1.2)\n",
    "tfmodel.fit(tfX_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfpredictions = tfmodel.predict(tfidfVect.transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7696390126671006\n",
      "f1_score(weighted): 0.7677517288080807\n",
      "average_precision_score(weighted): 0.7428221173739502\n",
      "recall_score(weighted): 0.7696390126671006\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_val, tfpredictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_val, tfpredictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_val, tfpredictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_val, tfpredictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "testTfpredictions = tfmodel.predict(tfidfVect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7732515501033402\n",
      "f1_score(weighted): 0.7716449986387606\n",
      "average_precision_score(weighted): 0.7440795684885831\n",
      "recall_score(weighted): 0.7732515501033402\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_test, testTfpredictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_test, testTfpredictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_test, testTfpredictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_test, testTfpredictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest tfidf:\n",
      "['ðµð½ñ' 'm2e' 'shareholder' 'tweeterfollow' 'tweeteradder' 'relieve'\n",
      " 'h01jg' '05' 'casino' 'longestpoemintheworld']\n",
      "\n",
      "Largest tfidf: \n",
      "['øªù' 'sniff' 'was' 'cry' 'crucifire' 'gutted' 'guys' 'ace' 'wants' 'smh']\n"
     ]
    }
   ],
   "source": [
    "tffeature_names = np.array(tfidfVect.get_feature_names())\n",
    "\n",
    "sorted_tfidf_index = tfX_train_vectorized.max(0).toarray()[0].argsort()\n",
    "\n",
    "print('Smallest tfidf:\\n{}\\n'.format(tffeature_names[sorted_tfidf_index[:10]]))\n",
    "print('Largest tfidf: \\n{}'.format(tffeature_names[sorted_tfidf_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['sad' 'sorry' 'sucks' 'miss' 'poor' 'wish' 'inaperfectworld' 'sick'\n",
      " 'sadly' 'missed']\n",
      "\n",
      "Largest Coefs: \n",
      "['thanks' 'welcome' 'great' 'thank' 'followfriday' 'glad' 'musicmonday'\n",
      " 'congrats' 'awesome' 'worry']\n"
     ]
    }
   ],
   "source": [
    "tfsorted_coef_index = tfmodel.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(tffeature_names[tfsorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(tffeature_names[tfsorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(tfmodel.predict(tfidfVect.transform(['love',\n",
    "                                    'working'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26804\n"
     ]
    }
   ],
   "source": [
    "ngramVect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train)\n",
    "print(len(ngramVect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.3, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngramX_train_vectorized = ngramVect.transform(X_train)\n",
    "ngramModel = LogisticRegression(C = 0.3)\n",
    "ngramModel.fit(ngramX_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngramPredictions = ngramModel.predict(ngramVect.transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7764482050768537\n",
      "f1_score(weighted): 0.7744223544637212\n",
      "average_precision_score(weighted): 0.7480119727722014\n",
      "recall_score(weighted): 0.7764482050768537\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_val, ngramPredictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_val, ngramPredictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_val, ngramPredictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_val, ngramPredictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testNgramPredictions = ngramModel.predict(ngramVect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.7769184612307487\n",
      "f1_score(weighted): 0.7751548322598547\n",
      "average_precision_score(weighted): 0.746587773774744\n",
      "recall_score(weighted): 0.7769184612307487\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_test, testNgramPredictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_test, testNgramPredictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_test, testNgramPredictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_test, testNgramPredictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['sad' 'inaperfectworld' 'poor' 'sucks' 'dontyouhate' 'missing' 'sadly'\n",
      " 'miss' 'sick' 'rip']\n",
      "\n",
      "Largest Coefs: \n",
      "['cant wait' 'no problem' 'welcome' 'thanks' 'musicmonday' 'followfriday'\n",
      " 'congrats' 'congratulations' 'no prob' 'sweet']\n"
     ]
    }
   ],
   "source": [
    "ngramfeature_names = np.array(ngramVect.get_feature_names())\n",
    "\n",
    "ngramsorted_coef_index = ngramModel.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(ngramfeature_names[ngramsorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(ngramfeature_names[ngramsorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "print(ngramModel.predict(ngramVect.transform(['phone is good', 'horrible person'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfVect = CountVectorizer(min_df=5).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature count: 9308\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature count:\", len(clfVect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfX_train_vectorized = clfVect.transform(X_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NuSVC(cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape='ovr', degree=2, gamma='auto', kernel='poly',\n",
       "   max_iter=-1, nu=0.5, probability=False, random_state=None,\n",
       "   shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.NuSVC(kernel = 'poly', degree = 2)\n",
    "clf.fit(clfX_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfpredictions = clf.predict(clfVect.transform(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.5376758624142592\n",
      "f1_score(weighted): 0.42339713718934374\n",
      "average_precision_score(weighted): 0.5585155187941309\n",
      "recall_score(weighted): 0.5376758624142592\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_val, clfpredictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_val, clfpredictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_val, clfpredictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_val, clfpredictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestClfpredictions = clf.predict(clfVect.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.5273018201213414\n",
      "f1_score(weighted): 0.4126559747863872\n",
      "average_precision_score(weighted): 0.5510158445950867\n",
      "recall_score(weighted): 0.5273018201213414\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score\", accuracy_score(y_test, TestClfpredictions))\n",
    "print(\"f1_score(weighted):\", f1_score(y_test, TestClfpredictions, average = 'weighted'))\n",
    "print(\"average_precision_score(weighted):\", average_precision_score(y_test, TestClfpredictions, average = 'weighted'))\n",
    "print(\"recall_score(weighted):\", recall_score(y_test, TestClfpredictions, average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest Coefs:\n",
      "['farrah' 'leak' 'no1' 'dontyouhate' '½o' 'upsetting' 'raincheck' 'boooo'\n",
      " 'heartbreaking' 'canceled']\n",
      "\n",
      "Largest Coefs: \n",
      "['geeks' 'whew' 'char_x3' 'iluu' 'arabidopsis' 'encourage' 'combine'\n",
      " 'rollin' 'elmo' 'carpool']\n"
     ]
    }
   ],
   "source": [
    "clffeature_names = np.array(clfVect.get_feature_names())\n",
    "\n",
    "clfsorted_coef_index = clf.coef_[0].argsort()\n",
    "\n",
    "print('Smallest Coefs:\\n{}\\n'.format(clffeature_names[clfsorted_coef_index[:10]]))\n",
    "print('Largest Coefs: \\n{}'.format(clffeature_names[clfsorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repeat = True\n",
    "while repeat == True:\n",
    "    string = input(\"Enter custom string:(0 to exit)\")\n",
    "    if string != '0':\n",
    "        print(ngramModel.predict(ngramVect.transform([string])))\n",
    "    else:\n",
    "        repeat = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
